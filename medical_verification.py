"""
ì „ë¬¸ì ì¸ ì˜ë£Œ ì •ë³´ ê²€ì¦ ì‹œìŠ¤í…œ (RAG ê¸°ë°˜)
"""

import re
import logging
import numpy as np
from typing import Dict, List, Any, Tuple
from dataclasses import dataclass, field

from config import config
from model_manager import model_manager

logger = logging.getLogger(__name__)

@dataclass
class VerificationResult:
    """ê²€ì¦ ê²°ê³¼ êµ¬ì¡°"""
    is_accurate: bool
    confidence_score: float  # 0-100
    evidence_sources: List[str]
    risk_level: str  # "low", "medium", "high"
    corrected_info: str
    warnings: List[str]
    professional_advice: str
    matched_keywords: List[str] = field(default_factory=list)
    triggered_rules: List[str] = field(default_factory=list)
    judgment: str = ""
    reason: str = ""

class MedicalFactChecker:
    """ì˜ë£Œ ì •ë³´ ì‚¬ì‹¤ í™•ì¸ ì‹œìŠ¤í…œ (RAG ê¸°ë°˜)"""
    
    def __init__(self):
        # ì„¤ì •ì—ì„œ í‚¤ì›Œë“œ ë¡œë“œ
        self.emergency_keywords = config.verification.EMERGENCY_KEYWORDS
        self.high_risk_keywords = config.verification.HIGH_RISK_KEYWORDS
        self.medium_risk_keywords = config.verification.MEDIUM_RISK_KEYWORDS
        self.confidence_threshold = config.verification.MIN_CONFIDENCE_THRESHOLD
        
        # ìœ„í—˜í•œ ì˜ë£Œ ì •ë³´ íŒ¨í„´ (ì •ê·œì‹)
        self.danger_patterns = [
            r'ìê°€ì¹˜ë£Œ.*ê°€ëŠ¥',
            r'ë³‘ì›.*ê°€ì§€.*ì•Šì•„ë„',
            r'ì•½.*ë¨¹ì§€.*ì•Šì•„ë„',
            r'ìœ„í—˜í•˜ì§€.*ì•Š',
            r'ê´œì°®ë‹¤',
            r'ë¬¸ì œì—†ë‹¤'
        ]

        # RAG ê¸°ë°˜ ì‹œìŠ¤í…œìœ¼ë¡œ ì „í™˜ - í•˜ë“œì½”ë”©ëœ íŒ¨í„´ ì œê±°
        # ëª¨ë“  ì˜ë£Œ ê´€ë ¨ í…ìŠ¤íŠ¸ë¥¼ RAGë¡œ íŒë‹¨
        
        # ë¯¼ê°„ìš”ë²• ê´€ë ¨ í‚¤ì›Œë“œ
        self.folk_remedy_keywords = [
            'ë¯¼ê°„ìš”ë²•', 'í•œë°©', 'ì•½ì´ˆ', 'ìƒê°•', 'ë§ˆëŠ˜', 'ê¿€', 'ë ˆëª¬', 'ì–‘íŒŒ',
            'ê°ì´ˆ', 'ì¸ì‚¼', 'í™ì‚¼', 'ë…¹ì°¨', 'ìš°ì—‰', 'ë„ë¼ì§€', 'ì˜¤ê°€í”¼',
            'ì°¨ê°€ë²„ì„¯', 'ì˜ì§€ë²„ì„¯', 'ìƒí™©ë²„ì„¯', 'ë²„ì„¯', 'ì‘¥', 'ë½•ì',
            'ê°ì´ˆì°¨', 'ìƒê°•ì°¨', 'ë§ˆëŠ˜ì°¨', 'ê¿€ë¬¼', 'ë ˆëª¬ì°¨', 'ì–‘íŒŒì¦™',
            'ë„ë¼ì§€ì°¨', 'ì˜¤ê°€í”¼ì°¨', 'ì‘¥ì°¨', 'ë½•ìì°¨', 'ê°ì´ˆì¦™', 'ìƒê°•ì¦™',
            'ë§ˆëŠ˜ì¦™', 'ê¿€ì¦™', 'ë ˆëª¬ì¦™', 'ì–‘íŒŒì¦™', 'ë„ë¼ì§€ì¦™', 'ì˜¤ê°€í”¼ì¦™',
            'ì‘¥ì¦™', 'ë½•ìì¦™', 'ê°ì´ˆê°€ë£¨', 'ìƒê°•ê°€ë£¨', 'ë§ˆëŠ˜ê°€ë£¨', 'ê¿€ê°€ë£¨',
            'ë ˆëª¬ê°€ë£¨', 'ì–‘íŒŒê°€ë£¨', 'ë„ë¼ì§€ê°€ë£¨', 'ì˜¤ê°€í”¼ê°€ë£¨', 'ì‘¥ê°€ë£¨', 'ë½•ìê°€ë£¨',
            'ë¯¼ê°„ì²˜ë°©', 'ê°€ì •ìš”ë²•', 'ìì—°ì¹˜ë£Œ', 'ì „í†µì˜í•™', 'í•œì˜í•™',
            'ì¹¨', 'ëœ¸', 'ë¶€í•­', 'ì§€ì••', 'ë§ˆì‚¬ì§€', 'ì•„ë¡œë§ˆ', 'ì—ì„¼ì…œì˜¤ì¼',
            'ì•„ë¡œë§ˆí…Œë¼í”¼', 'ì—ì„¼ì…œì˜¤ì¼í…Œë¼í”¼', 'ì•„ë¡œë§ˆì˜¤ì¼', 'ì—ì„¼ì…œì˜¤ì¼',
            'ì•„ë¡œë§ˆí…Œë¼í”¼', 'ì—ì„¼ì…œì˜¤ì¼í…Œë¼í”¼', 'ì•„ë¡œë§ˆì˜¤ì¼', 'ì—ì„¼ì…œì˜¤ì¼',
            # ë¹„ê°•/ì½” ì„¸ì²™Â·ë¶„ì‚¬ ê´€ë ¨ í‘œí˜„ (ë™ì  íŒë³„ ê°•í™”ë¥¼ ìœ„í•œ ì¼ë°˜í™” í‚¤ì›Œë“œ)
            'ì†Œê¸ˆë¬¼', 'ì‹ì—¼ìˆ˜', 'ë¹„ê°•ì„¸ì²™', 'ì½”ì„¸ì²™', 'ë¹„ê°• ìŠ¤í”„ë ˆì´', 'ì½” ìŠ¤í”„ë ˆì´', 'ë¶„ë¬´ê¸°'
        ]
    
    async def analyze_medical_claim(self, text: str, evidence_docs: List[Dict]) -> VerificationResult:
        """ì˜ë£Œ ì£¼ì¥ ë¶„ì„ ë° ê²€ì¦ (RAG ê¸°ë°˜)"""
        
        # 1. ìœ„í—˜ë„ í‰ê°€
        risk_level = self._assess_risk_level(text)
        
        # 2. ì‚¬ì‹¤ í™•ì¸
        accuracy_score, evidence = self._verify_against_sources(text, evidence_docs)
        
        # 3. ê²½ê³ ì‚¬í•­ ì¶”ì¶œ
        warnings = self._extract_warnings(text, evidence_docs)
        
        # 4. ì •ì •ëœ ì •ë³´ ìƒì„±
        corrected_info = await self._generate_corrected_info(text, evidence_docs)
        
        # 5. ì „ë¬¸ê°€ ì¡°ì–¸ ìƒì„±
        professional_advice = self._generate_professional_advice(text, risk_level)
        
        # 6. ì„¤ëª… ìš”ì†Œ ìˆ˜ì§‘ (ë§¤ì¹­ í‚¤ì›Œë“œ/ê·œì¹™)
        matched_keywords = self._extract_keywords(text)[:5]
        triggered_rules: List[str] = []
        
        # RAG ê¸°ë°˜ ê·œì¹™ íŠ¸ë¦¬ê±° íƒì§€ - í•˜ë“œì½”ë”© ì œê±°
        # ëª¨ë“  íŒë‹¨ì€ RAGê°€ ë²¡í„° DBì˜ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ìˆ˜í–‰
        
        # 7. íŒë‹¨ ë¼ë²¨ ë° ì´ìœ  ìƒì„±
        has_evidence = bool(evidence_docs)
        judgment = self._determine_judgment(text, accuracy_score, triggered_rules, warnings, has_evidence)
        reason_text = self._generate_detailed_reason(text, judgment, accuracy_score, has_evidence, evidence_docs, warnings)
        
        logger.info(f"VerificationResult ìƒì„±: evidence_docs ê°œìˆ˜ = {len(evidence_docs)}")
        evidence_sources = [doc['content'][:200] + "..." for doc in evidence_docs]
        logger.info(f"VerificationResult ìƒì„±: evidence_sources ê°œìˆ˜ = {len(evidence_sources)}")
        
        return VerificationResult(
            is_accurate=accuracy_score > self.confidence_threshold,
            confidence_score=accuracy_score,
            evidence_sources=evidence_sources,
            risk_level=risk_level,
            corrected_info=corrected_info,
            warnings=warnings,
            professional_advice=professional_advice,
            matched_keywords=matched_keywords,
            triggered_rules=triggered_rules,
            judgment=judgment,
            reason=reason_text
        )

    def _determine_judgment(self, text: str, score: float, triggered_rules: List[str], warnings: List[str], has_evidence: bool) -> str:
        """ì˜ë£Œ ì •ë³´ íŒë‹¨ ê²°ê³¼ ê²°ì • (ë¯¼ê°„ìš”ë²•/ì˜¬ë°”ë¥¸/íŒë‹¨í•˜ê¸° ì–´ë ¤ìš´/ì˜¬ë°”ë¥´ì§€ ì•Šì€)"""
        
        # 1. ë¯¼ê°„ìš”ë²• ê°ì§€
        if self._is_folk_remedy(text):
            return "ë¯¼ê°„ìš”ë²• ê´€ë ¨ ì •ë³´"
        
        # 2. ëª…ë°±í•œ ëª¨ìˆœ/ë°˜ì¦ ì£¼ì¥ ê°ì§€ ì‹œ ì¦‰ì‹œ 'ì˜¬ë°”ë¥´ì§€ ì•Šì€ ì •ë³´'
        if self._has_contradiction_claim(text):
            return "ì˜¬ë°”ë¥´ì§€ ì•Šì€ ì •ë³´"

        # 3. ì‹ ë¢°ë„ ê¸°ë°˜ íŒë‹¨ (ë‹¨ìˆœ 4ë¶„ë¥˜)
        if score >= 70:
            return "ì˜¬ë°”ë¥¸ ì˜ë£Œ ì •ë³´"
        elif score >= 40:
            return "íŒë‹¨í•˜ê¸° ì–´ë ¤ìš´ ì •ë³´"
        else:
            return "ì˜¬ë°”ë¥´ì§€ ì•Šì€ ì •ë³´"
    
    def _assess_risk_level(self, text: str) -> str:
        """ìœ„í—˜ë„ í‰ê°€"""
        text_lower = text.lower()
        
        # ì„¤ì •ì—ì„œ í‚¤ì›Œë“œ ì‚¬ìš©
        if any(keyword in text_lower for keyword in self.high_risk_keywords):
            return "high"
        elif any(keyword in text_lower for keyword in self.medium_risk_keywords):
            return "medium"
        else:
            return "low"
    
    def _verify_against_sources(self, text: str, evidence_docs: List[Dict]) -> Tuple[float, List[str]]:
        """RAG ê¸°ë°˜ ì¶œì²˜ ëŒ€ë¹„ ì‚¬ì‹¤ í™•ì¸"""
        if not evidence_docs:
            return 30.0, []  # ê·¼ê±° ì—†ìŒ
        
        # RAG ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°
        try:
            # í‚¤ì›Œë“œ ê²¹ì¹¨ ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚° (ë” ì •í™•í•œ ë°©ë²•)
            try:
                from api_handlers import APIHandlers
                q_keywords = APIHandlers._extract_core_keywords(text)
                q_text_lower = text.lower()
                total_score = 0.0
                max_score = 0.0
                
                for doc in evidence_docs:  # ëª¨ë“  ë¬¸ì„œ ì‚¬ìš©
                    doc_tokens = set(re.findall(r'[ê°€-í£A-Za-z0-9]+', (doc.get('content') or '').lower()))
                    overlap = len(q_keywords & doc_tokens)
                    ratio = overlap / max(1, len(q_keywords))
                    
                    # í‚¤ì›Œë“œ ê²¹ì¹¨ë¥ ì— ë”°ë¥¸ ì ìˆ˜ ê³„ì‚° (ë” ë†’ì€ ì ìˆ˜)
                    if ratio >= 0.7:  # 70% ì´ìƒ ê²¹ì¹¨
                        doc_score = 95.0 + (ratio - 0.7) * 16.7  # 95-100ì 
                    elif ratio >= 0.5:  # 50% ì´ìƒ ê²¹ì¹¨
                        doc_score = 85.0 + (ratio - 0.5) * 50.0  # 85-95ì 
                    elif ratio >= 0.3:  # 30% ì´ìƒ ê²¹ì¹¨
                        doc_score = 70.0 + (ratio - 0.3) * 75.0  # 70-85ì 
                    elif ratio >= 0.2:  # 20% ì´ìƒ ê²¹ì¹¨
                        doc_score = 50.0 + (ratio - 0.2) * 200.0  # 50-70ì 
                    else:  # 20% ë¯¸ë§Œ
                        doc_score = 30.0 + ratio * 100.0  # 30-50ì 
                    
                    # Distance ê¸°ë°˜ ë³´ì • (ì‘ì€ ì˜í–¥)
                    distance = float(doc.get('distance', 1.0))
                    distance_bonus = max(0.0, (1.0 - distance) * 10.0)  # ìµœëŒ€ 10ì  ë³´ë„ˆìŠ¤
                    
                    final_doc_score = min(100.0, doc_score + distance_bonus)
                    total_score += final_doc_score
                    max_score = max(max_score, final_doc_score)
                
                # ìµœì¢… ì‹ ë¢°ë„: ê°€ì¥ ë†’ì€ ì ìˆ˜ì™€ í‰ê·  ì ìˆ˜ì˜ ê°€ì¤‘ í‰ê· 
                avg_score = total_score / len(evidence_docs)
                final_score = (max_score * 0.7) + (avg_score * 0.3)
                
                # ê³„ì‚°ëœ ì‹ ë¢°ë„ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ê°•ì œ ìµœì†Œê°’ ì œê±°)
                final_score = min(100.0, final_score)

                # ëª¨ìˆœ(ë°˜ì¦) ì‹ í˜¸ í˜ë„í‹° ì ìš©: ì¿¼ë¦¬ ì§„ìˆ ê³¼ ê·¼ê±° ë¬¸ì„œì˜ í•µì‹¬ ê°œë…ì´ ìƒì¶©í•˜ëŠ” ê²½ìš°
                try:
                    evidence_text = "\n".join([str(d.get('content','')) for d in evidence_docs]).lower()
                    contradiction_penalty = 0.0
                    # ì •ê·œì‹ ê¸°ë°˜ ëª¨ìˆœ íƒì§€ í™•ëŒ€
                    import re as _re
                    contradiction_rules = [
                        # ì„¸ê·  vs ë°”ì´ëŸ¬ìŠ¤
                        (r'(ì„¸ê· |ë°•í…Œë¦¬ì•„)', r'(ë°”ì´ëŸ¬ìŠ¤|virus)', 40.0),
                        # ì „ì—¼ ì•ˆ ëœë‹¤ vs ì „ì—¼/ì „íŒŒ/ê²½êµ¬ ê°ì—¼
                        (r'(ì „ì—¼(ë˜)?ì§€\s*ì•Š|ì „ì—¼ì„±\s*ì—†)', r'(ì „ì—¼|ì „íŒŒ|ê²½êµ¬)', 40.0),
                        # ë°±ì‹  ë¶ˆí•„ìš” vs ì ‘ì¢…/ê¶Œì¥/ë°±ì‹ 
                        (r'(ë°±ì‹ |ì˜ˆë°©\s*ì ‘ì¢…).*(í•„ìš”\s*ì—†|ë¶ˆí•„ìš”)', r'(ì ‘ì¢…|ë°±ì‹ |ê¶Œì¥)', 35.0),
                        # ì¹˜ë£Œì œ ìˆë‹¤ vs ì¹˜ë£Œì œ ì—†ìŒ/íŠ¹ì´ì  ì¹˜ë£Œ ì—†ìŒ
                        (r'(ì¹˜ë£Œì œ|íŠ¹íš¨(ì•½|ì¹˜ë£Œì œ)).*(ìˆ)', r'(ì¹˜ë£Œì œ|íŠ¹ì´ì \s*ì¹˜ë£Œ).*(ì—†)', 35.0),
                        # í˜ˆì•¡í˜• ì˜¤ì¸: í˜ˆì•¡í˜•ê³¼ ê°ì—¼ ì·¨ì•½ì„± ë‹¨ì •
                        (r'(í˜ˆì•¡í˜•).*(ì˜\s*ê±¸|ì·¨ì•½|ìœ„í—˜|ë†’)', r'(aí˜•\s*ê°„ì—¼|aí˜•ê°„ì—¼|hepatitis\s*a|ê°„ì—¼)', 40.0),
                        # ë§Œì„±í™” ì˜¤ì¸: HAVëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë§Œì„±í™”í•˜ì§€ ì•ŠìŒ
                        (r'(aí˜•\s*ê°„ì—¼|aí˜•ê°„ì—¼|hepatitis\s*a).*(ë§Œì„±|ê°„ê²½ë³€|ê°„ì•”).*ë°˜ë“œì‹œ|í•­ìƒ', r'', 35.0),
                        # ë°±ì‹ ì´ ë³€ì´ë¥¼ ìœ ë°œí•œë‹¤ëŠ” ì£¼ì¥
                        (r'(ë°±ì‹ |ì˜ˆë°©\s*ì ‘ì¢…).*(ë³€ì´|ëŒì—°ë³€ì´).*(ìœ ë°œ|ì´ˆë˜|ìƒì„±)', r'', 35.0),
                    ]
                    for q_pat, e_pat, pen in contradiction_rules:
                        if _re.search(q_pat, q_text_lower) and _re.search(e_pat, evidence_text):
                            contradiction_penalty += pen

                    # ê·¼ê±° ë¬¸ì„œì— ëª…ì‹œê°€ ë¶€ì¡±í•´ë„, ì§ˆí™˜ ìƒì‹ ê¸°ë°˜ ë³´ì • (HAVëŠ” ì „ì—¼ì„± ìˆìŒ, ë°±ì‹  ê¶Œì¥, íŠ¹ì´ì  ì¹˜ë£Œì œ ì—†ìŒ)
                    hepatitis_hints = any(tok in q_text_lower for tok in ['aí˜•ê°„ì—¼', 'aí˜• ê°„ì—¼', 'aí˜•ê°ì—¼', 'hepatitis a', 'ê°„ì—¼'])
                    if hepatitis_hints:
                        if _re.search(r'(ì „ì—¼(ë˜)?ì§€\s*ì•Š|ì „ì—¼ì„±\s*ì—†)', q_text_lower):
                            contradiction_penalty += 25.0
                        if _re.search(r'(ë°±ì‹ |ì˜ˆë°©\s*ì ‘ì¢…).*(í•„ìš”\s*ì—†|ë¶ˆí•„ìš”)', q_text_lower):
                            contradiction_penalty += 20.0
                        if _re.search(r'(ì¹˜ë£Œì œ|íŠ¹íš¨(ì•½|ì¹˜ë£Œì œ)).*(ìˆ)', q_text_lower):
                            contradiction_penalty += 20.0

                    if contradiction_penalty > 0:
                        final_score = max(10.0, final_score - contradiction_penalty)
                        # ëª¨ìˆœ íƒì§€ ì‹œ ìƒí•œ ìº¡: ì‹ ë¢°ë„ 35% ì´í•˜ë¡œ ì œí•œ
                        final_score = min(final_score, 35.0)
                except Exception:
                    pass
                
                return final_score, [doc['content'][:150] for doc in evidence_docs]
                
            except Exception as e:
                logger.warning(f"í‚¤ì›Œë“œ ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
                # ê¸°ì¡´ distance ê¸°ë°˜ ê³„ì‚°ìœ¼ë¡œ fallback
                distances = [float(d.get('distance', 1.0)) for d in evidence_docs]
                if distances:
                    best_d = min(max(0.0, d) for d in distances)
                    db_sim = max(0.0, 1.0 - min(1.0, best_d))
                    base = db_sim * 100.0
                    return min(100.0, base), [doc['content'][:150] for doc in evidence_docs]
                
        except Exception as e:
            logger.warning(f"ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        return 50.0, []  # ê¸°ë³¸ê°’
    
    def _extract_keywords(self, text: str) -> List[str]:
        """RAG ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ - ê°„ë‹¨í•œ í† í°í™”ë§Œ ìˆ˜í–‰"""
        tokens = re.findall(r'[ê°€-í£A-Za-z0-9]+', text)
        return tokens[:5]  # ìƒìœ„ 5ê°œë§Œ ë°˜í™˜
    
    def _extract_warnings(self, text: str, evidence_docs: List[Dict]) -> List[str]:
        """RAG ê¸°ë°˜ ê²½ê³ ì‚¬í•­ ì¶”ì¶œ"""
        warnings = []
        
        # ë¶ˆì™„ì „í•œ ì •ë³´ ê²½ê³ 
        if not evidence_docs:
            warnings.append("âš ï¸ í•´ë‹¹ ì •ë³´ì— ëŒ€í•œ ê³µì‹ ì˜ë£Œ ìë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì‘ê¸‰ìƒí™© í‚¤ì›Œë“œ ê°ì§€ (ì„¤ì •ì—ì„œ ë¡œë“œ)
        if any(keyword in text for keyword in self.emergency_keywords):
            warnings.append("ğŸš¨ ì‘ê¸‰ìƒí™©ì´ ì˜ì‹¬ë˜ë©´ ì¦‰ì‹œ 119ì— ì‹ ê³ í•˜ê±°ë‚˜ ì‘ê¸‰ì‹¤ì„ ë°©ë¬¸í•˜ì„¸ìš”.")
        
        return warnings
    
    async def _generate_corrected_info(self, text: str, evidence_docs: List[Dict]) -> str:
        """RAG ê¸°ë°˜ ì •ì •ëœ ì •ë³´ ìƒì„±"""
        if not evidence_docs:
            return "í•´ë‹¹ ì •ë³´ì— ëŒ€í•œ ê³µì‹ ì˜ë£Œ ìë£Œë¥¼ ì°¾ê¸° ì–´ë µìŠµë‹ˆë‹¤."
        
        # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œì˜ í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œ
        try:
            best_doc = evidence_docs[0]['content']
            
            # ê¹¨ì§„ ë¬¸ì ì œê±° ë° ì •ë¦¬
            cleaned_doc = best_doc.replace('', '').replace('', '').replace('', '')
            
            # RAG ê¸°ë°˜ìœ¼ë¡œ ë²¡í„° DBì˜ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ íŒë‹¨
            # í•˜ë“œì½”ë”©ëœ í•„í„°ë§ ì œê±° - ëª¨ë“  ì˜ë£Œ ê´€ë ¨ í…ìŠ¤íŠ¸ë¥¼ íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ í•¨
            
            # RAG ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ì •ë³´ë§Œ ì¶”ì¶œ
            try:
                from model_manager import model_manager
                
                rag_prompt = f"""ë‹¤ìŒ ì˜ë£Œ ì •ë³´ì— ëŒ€í•œ ì •í™•í•œ ì„¤ëª…ì„ ì œê³µí•´ì£¼ì„¸ìš”:

ì‚¬ìš©ì ì§ˆë¬¸: {text}

ì°¸ê³  ë¬¸ì„œ:
{cleaned_doc}

ìœ„ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ì˜í•™ ì •ë³´ë§Œì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ì¤‘ìš”í•œ ê·œì¹™:
1. ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ë‚´ìš©ë§Œ í¬í•¨í•˜ì„¸ìš”
2. ê´€ë ¨ì´ ì—†ëŠ” ë‚´ìš©(ì˜ˆ: ëŒ€ì¥, ì†Œì¥, ìš©ì¢… ë“±)ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
3. ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€ì´ ë˜ë„ë¡ í•˜ì„¸ìš”
4. ì˜í•™ì ìœ¼ë¡œ ì •í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”

ë§Œì•½ ì°¸ê³  ë¬¸ì„œê°€ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ì—†ë‹¤ë©´ "ê´€ë ¨ëœ ì˜í•™ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µë³€í•˜ì„¸ìš”."""

                rag_result = await model_manager.generate_response(
                    prompt=rag_prompt,
                    system_prompt="ë‹¹ì‹ ì€ ì˜ë£Œ ì •ë³´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ì˜í•™ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.",
                    context="",
                    max_new_tokens=100,
                    do_sample=False,
                    temperature=0.3
                )
                
                if rag_result.get("success"):
                    return rag_result.get("response", "").strip()
                else:
                    # RAG ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì²˜ë¦¬
                    sentences = cleaned_doc.split('.')
                    clean_sentences = []
                    
                    for sentence in sentences[:3]:  # ìµœëŒ€ 3ë¬¸ì¥ê¹Œì§€ë§Œ
                        sentence = sentence.strip()
                        if len(sentence) > 10 and len(sentence) < 200:  # ì ì ˆí•œ ê¸¸ì´ì˜ ë¬¸ì¥ë§Œ
                            clean_sentences.append(sentence)
                    
                    if clean_sentences:
                        return '. '.join(clean_sentences) + '.'
                    else:
                        return cleaned_doc[:300] + "..." if len(cleaned_doc) > 300 else cleaned_doc
                        
            except Exception as e:
                logger.warning(f"RAG ì²˜ë¦¬ ì‹¤íŒ¨, ê¸°ë³¸ ì²˜ë¦¬ ì‚¬ìš©: {e}")
                # RAG ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì²˜ë¦¬
                sentences = cleaned_doc.split('.')
                clean_sentences = []
                
                for sentence in sentences[:3]:  # ìµœëŒ€ 3ë¬¸ì¥ê¹Œì§€ë§Œ
                    sentence = sentence.strip()
                    if len(sentence) > 10 and len(sentence) < 200:  # ì ì ˆí•œ ê¸¸ì´ì˜ ë¬¸ì¥ë§Œ
                        clean_sentences.append(sentence)
                
                if clean_sentences:
                    return '. '.join(clean_sentences) + '.'
                else:
                    return cleaned_doc[:300] + "..." if len(cleaned_doc) > 300 else cleaned_doc
                
        except Exception as e:
            logger.warning(f"ì •ì • ì •ë³´ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ê´€ë ¨ ì˜ë£Œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    def _generate_detailed_reason(self, text: str, judgment: str, score: float, has_evidence: bool, evidence_docs: List[Dict], warnings: List[str]) -> str:
        """ìƒì„¸í•œ íŒë‹¨ ê·¼ê±° ìƒì„± - ê°„ê²°í•˜ê³  ë˜ë ·í•œ í˜•ì‹"""
        
        reason_parts = []
        
        # 1. í•µì‹¬ íŒë‹¨ ê·¼ê±° (1ë¬¸ì¥, ìµœëŒ€ 80ì)
        if judgment == "ë¯¼ê°„ìš”ë²• ê´€ë ¨ ì •ë³´":
            core_reason = "ë¯¼ê°„ìš”ë²• ê´€ë ¨ í‚¤ì›Œë“œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."
        elif judgment == "ì˜¬ë°”ë¥¸ ì˜ë£Œ ì •ë³´":
            if has_evidence:
                core_reason = "ê³µì‹ ì˜ë£Œ ìë£Œì™€ ì¼ì¹˜í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤."
            else:
                core_reason = "ì˜í•™ì ìœ¼ë¡œ ì •í™•í•œ ì •ë³´ë¡œ íŒë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤."
        elif judgment == "íŒë‹¨í•˜ê¸° ì–´ë ¤ìš´ ì •ë³´":
            core_reason = "ì¶©ë¶„í•œ ì˜ë£Œ ê·¼ê±°ê°€ ì—†ì–´ ì •í™•ì„±ì„ íŒë‹¨í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."
        elif judgment == "ë¶€ë¶„ì ìœ¼ë¡œ ì •í™•í•œ ì •ë³´":
            core_reason = "ì¼ë¶€ ë‚´ìš©ì€ ì •í™•í•˜ì§€ë§Œ ì „ì²´ì ì¸ ì •í™•ì„±ì„ í™•ì‹ í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."
        elif judgment == "ì˜¬ë°”ë¥´ì§€ ì•Šì€ ì •ë³´":
            core_reason = "ì˜ë£Œ ìë£Œì™€ ì¼ì¹˜í•˜ì§€ ì•Šê±°ë‚˜ ì˜ëª»ëœ ì •ë³´ë¡œ íŒë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤."
        else:
            core_reason = "ì˜ë£Œ ì •ë³´ì˜ ì •í™•ì„±ì„ ê²€í† í–ˆìŠµë‹ˆë‹¤."
        
        reason_parts.append(core_reason)
        
        # 2. ì‹ ë¢°ë„ ì ìˆ˜ ì„¤ëª… (ì „ êµ¬ê°„ ë™ì¼ í¬ë§·)
        score_desc = f"ì‹ ë¢°ë„ ì ìˆ˜ {score:.0f}%."
        
        reason_parts.append(score_desc)
        
        # 3. ê·¼ê±° ë¬¸ì„œ ìƒíƒœ (ê°„ê²°í•˜ê²Œ)
        if has_evidence:
            doc_count = len(evidence_docs)
            reason_parts.append(f"ì˜ë£Œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ {doc_count}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        else:
            reason_parts.append("ì˜ë£Œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì „ì²´ ê¸¸ì´ ì œí•œ (ìµœëŒ€ 200ì)
        full_reason = " ".join(reason_parts)
        if len(full_reason) > 200:
            # ì•ì˜ 2ê°œ ë¬¸ì¥ë§Œ ìœ ì§€
            return " ".join(reason_parts[:2])
        
        return full_reason
    
    def _is_folk_remedy(self, text: str) -> bool:
        """ë¯¼ê°„ìš”ë²• ê´€ë ¨ ì •ë³´ì¸ì§€ ê°ì§€"""
        text_lower = text.lower()
        
        # ë¯¼ê°„ìš”ë²• í‚¤ì›Œë“œ ê°ì§€
        folk_keyword_count = sum(1 for keyword in self.folk_remedy_keywords if keyword in text_lower)
        
        # ë¯¼ê°„ìš”ë²• íŒ¨í„´ ê°ì§€
        folk_patterns = [
            r'ë¨¹ìœ¼ë©´.*ì¢‹ë‹¤',
            r'ë§ˆì‹œë©´.*ì¢‹ë‹¤',
            r'ë°”ë¥´ë©´.*ì¢‹ë‹¤',
            r'ë¶™ì´ë©´.*ì¢‹ë‹¤',
            r'ì°œì§ˆí•˜ë©´.*ì¢‹ë‹¤',
            r'ë§ˆì‚¬ì§€í•˜ë©´.*ì¢‹ë‹¤',
            r'ì°¨ë¡œ.*ë§ˆì‹œë©´',
            r'ì¦™ìœ¼ë¡œ.*ë§ˆì‹œë©´',
            r'ê°€ë£¨ë¡œ.*ë¨¹ìœ¼ë©´',
            r'í•œë°©.*ì¹˜ë£Œ',
            r'ë¯¼ê°„.*ì¹˜ë£Œ',
            r'ìì—°.*ì¹˜ë£Œ',
            r'ì „í†µ.*ì¹˜ë£Œ',
            # ë¹„ê°•/ì½”ì— íŠ¹ì • ì•¡ì²´ë¥¼ ë¶„ì‚¬Â·ì„¸ì²™í•˜ì—¬ ì˜ˆë°©/ì¹˜ë£Œí•œë‹¤ê³  ì£¼ì¥í•˜ëŠ” íŒ¨í„´
            r'(ì†Œê¸ˆë¬¼|ì‹ì—¼ìˆ˜).*(ì½”|ë¹„ê°•).*(ë¿Œë¦¬|ë¶„ì‚¬|ìŠ¤í”„ë ˆì´|ì„¸ì²™)',
            r'(ì†Œê¸ˆë¬¼|ì‹ì—¼ìˆ˜).*(ì½”ë¡œë‚˜|ê°ê¸°|ê°ì—¼).*(ì˜ˆë°©|ì¹˜ë£Œ)'
        ]
        
        folk_pattern_count = sum(1 for pattern in folk_patterns if re.search(pattern, text_lower))
        
        # ë¯¼ê°„ìš”ë²•ìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ê¸°ì¤€
        return folk_keyword_count >= 2 or folk_pattern_count >= 1

    def _has_contradiction_claim(self, text: str) -> bool:
        """ì¿¼ë¦¬ ìì²´ê°€ ì˜ë£Œ ìƒì‹ê³¼ ìƒì¶©í•˜ëŠ” ëŒ€í‘œì  ì£¼ì¥ì¸ì§€ íƒì§€ (ê°„ë‹¨ ê·œì¹™)"""
        t = (text or '').lower()
        import re as _re
        contradiction_patterns = [
            r'ì „ì—¼(ë˜)?ì§€\s*ì•Š',
            r'ì „ì—¼ì„±\s*ì—†',
            r'(ë°±ì‹ |ì˜ˆë°©\s*ì ‘ì¢…).*(í•„ìš”\s*ì—†|ë¶ˆí•„ìš”)',
            r'(ì¹˜ë£Œì œ|íŠ¹íš¨(ì•½|ì¹˜ë£Œì œ)).*(ìˆ)',
            r'(ì„¸ê· |ë°•í…Œë¦¬ì•„).*(ê°ì—¼)',
            # í˜ˆì•¡í˜• ê´€ë ¨ ì˜¤ì¸: í˜ˆì•¡í˜•ì— ë”°ë¼ ì˜ ê±¸ë¦°ë‹¤/ìœ„í—˜/ì·¨ì•½ ë“±
            r'(aí˜•\s*ê°„ì—¼|aí˜•ê°„ì—¼|ê°„ì—¼).*(í˜ˆì•¡í˜•).*(ì˜\s*ê±¸|ì·¨ì•½|ìœ„í—˜|ë†’)',
            r'(í˜ˆì•¡í˜•).*(aí˜•\s*ê°„ì—¼|aí˜•ê°„ì—¼|ê°„ì—¼).*(ì˜\s*ê±¸|ì·¨ì•½|ìœ„í—˜|ë†’)'
        ]
        return any(_re.search(p, t) for p in contradiction_patterns)
    
    def _generate_professional_advice(self, text: str, risk_level: str) -> str:
        """ì „ë¬¸ê°€ ì¡°ì–¸ ìƒì„±"""
        if risk_level == "high":
            return "ì˜ë£Œ ì „ë¬¸ê°€ ìƒë‹´ í•„ìˆ˜"
        elif risk_level == "medium":
            return "ì¦ìƒ ì§€ì† ì‹œ ì „ë¬¸ì˜ ìƒë‹´ ê¶Œì¥"
        else:
            return "ì •í™•í•œ ì§„ë‹¨ì€ ì˜ë£Œì§„ê³¼ ìƒë‹´"

def format_verification_report(result: VerificationResult, query: str) -> str:
    """ê°„ê²°í•œ ê²€ì¦ ê²°ê³¼ í˜•ì‹í™” - ì„¹ì…˜ë³„ ê¸¸ì´ ì œí•œ"""
    
    # ìµœìƒë‹¨ íŒë‹¨ ë¼ë²¨ ìƒì„±
    judgment_label = result.judgment or (
        "íŒë‹¨: ë§ìŒ" if result.confidence_score >= 70 else (
            "íŒë‹¨: í‹€ë¦¼" if (result.confidence_score <= 30 or any("ê³¼ì¥" in w or "ë¯¼ê°„ìš”ë²•" in w for w in result.warnings)) else "íŒë‹¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        )
    )

    # ì‹ ë¢°ë„ì— ë”°ë¥¸ ê°„ë‹¨í•œ ìƒíƒœ í‘œì‹œ
    if result.confidence_score >= 80:
        status = "ì‹ ë¢°í•  ìˆ˜ ìˆìŒ"
    elif result.confidence_score >= 60:
        status = "ë¶€ë¶„ì ìœ¼ë¡œ ë§ëŠ” ì •ë³´"
    else:
        status = "ì¶”ê°€ í™•ì¸ í•„ìš”"
    
    # í•µì‹¬ ì„¤ëª… ìƒì„± (1-2ë¬¸ì¥, ìµœëŒ€ 150ì) - ì§„ë‹¨ ìš©ì–´/ì£¼ì œ ë¶ˆì¼ì¹˜ í•„í„°ë§ ê°•í™”
    # í•µì‹¬ ì„¤ëª…ì€ 'ë§ìŒ/í‹€ë¦¼'ì¼ ë•Œë§Œ ìƒì„±. ê·¸ ì™¸ëŠ” ê°„ë‹¨ ë©”ì‹œì§€.
    if result.evidence_sources and (result.judgment or '') in ('ì˜¬ë°”ë¥¸ ì˜ë£Œ ì •ë³´', 'ì˜¬ë°”ë¥´ì§€ ì•Šì€ ì •ë³´'):
        try:
            main_info = result.evidence_sources[0]
            # ê¹¨ì§„ ë¬¸ì ì œê±°
            cleaned_info = main_info.replace('', '').replace('', '').replace('', '')
            # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸° (ìµœëŒ€ 2ë¬¸ì¥)
            sentences = re.split(r"[\.?!]\s+", cleaned_info)
            core_sentences = []
            total_length = 0
            
            # ì§„ë‹¨ ê´€ë ¨ í‚¤ì›Œë“œ í•„í„°ë§
            diagnostic_keywords = ['ë¯¸ë…¸ì „ì´íš¨ì†Œ', 'ast', 'got', 'ë¹Œë¦¬ë£¨ë¹ˆ', 'í˜ˆì²­', 'ìˆ˜ì¹˜', 'í™©ë‹¬', 'ê²€ì‚¬', 'ì§„ë‹¨']
            # ë¬´ê´€ ë„ë©”ì¸(ê³¤ì¶©/ê¸°ìƒì¶© ë“±) ë°°ì œ í‚¤ì›Œë“œ
            irrelevant_domain_keywords = ['ê³¤ì¶©', 'í¡í˜ˆ', 'ìœ ì¶©', 'ì„±ì¶©', 'ì•Œ(', 'ë²¼ë£©', 'ì´(', 'ì§„ë“œê¸°', 'ëª¨ê¸°']
            
            import re as _re
            query_tokens = set(_re.findall(r'[ê°€-í£A-Za-z0-9]+', (query or '').lower()))
            def is_topic_relevant(sent: str) -> bool:
                s_tokens = set(_re.findall(r'[ê°€-í£A-Za-z0-9]+', (sent or '').lower()))
                if not s_tokens:
                    return False
                overlap = len(query_tokens & s_tokens)
                overlap_ratio = overlap / max(1, len(query_tokens))
                # ì§ˆí™˜ íŠ¹ì •ì„±: ì§ˆì˜ì— íŠ¹ì • ì§ˆí™˜ í† í°ì´ ìˆìœ¼ë©´ ë¬¸ì¥ì—ë„ í•´ë‹¹ ì§ˆí™˜ í† í°ì´ ìˆì–´ì•¼ í•¨
                q_low = (query or '').lower()
                s_low = (sent or '').lower()
                hepA_q = any(t in q_low for t in ['aí˜•ê°„ì—¼', 'aí˜• ê°„ì—¼', 'aí˜•ê°ì—¼', 'hepatitis a'])
                hepA_s = any(t in s_low for t in ['aí˜•ê°„ì—¼', 'aí˜• ê°„ì—¼', 'hepatitis a'])
                dengue_q = any(t in q_low for t in ['ë…ê¸°', 'dengue'])
                dengue_s = any(t in s_low for t in ['ë…ê¸°', 'dengue'])
                if hepA_q and not hepA_s:
                    return False
                if dengue_q and not dengue_s:
                    return False
                return overlap_ratio >= 0.3
            
            for sentence in sentences[:8]:  # ë” ë§ì€ ë¬¸ì¥ ê²€í† 
                sentence = sentence.strip()
                if not sentence:
                    continue
                
                sentence_lower = sentence.lower()
                
                # ì§„ë‹¨ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ ì œì™¸
                has_diagnostic = any(kw in sentence_lower for kw in diagnostic_keywords)
                # ê³¤ì¶©/ê¸°ìƒì¶© ë“± ë¬´ê´€ ë„ë©”ì¸ ì œì™¸
                has_irrelevant_domain = any(kw in sentence_lower for kw in irrelevant_domain_keywords)
                # ì£¼ì œ ì¼ì¹˜ ì—¬ë¶€
                topic_ok = is_topic_relevant(sentence)
                
                # ë¶ˆì™„ì „/ìƒëµë¶€í˜¸ ë¬¸ì¥ ì œì™¸
                if ('...' in sentence) or ('â€¦' in sentence) or re.search(r'[\.]{2,}$', sentence):
                    continue
                if re.search(r'(ìœ¼ë¡œ|ë¡œ|ë©°|ê³ |ë“±)$', sentence):
                    continue
                # ì¿¼ë¦¬ì™€ ê´€ë ¨ì„± ìˆëŠ” í‚¤ì›Œë“œ í™•ì¸ (í•©ë³‘ì¦ ì§ˆì˜ì˜ ê²½ìš°)
                if 'í•©ë³‘ì¦' in query.lower():
                    complication_keywords = ['í•©ë³‘ì¦', 'ê¸°ì•µ-ë°”ë ˆì¦í›„êµ°', 'ê¸‰ì„± ì‹ ë¶€ì „', 'ë‹´ë‚­ì—¼', 'ì·Œì¥ì—¼', 'í˜ˆê´€ì—¼', 'ê´€ì ˆì—¼']
                    has_complication = any(kw in sentence_lower for kw in complication_keywords)
                    
                    # í•©ë³‘ì¦ ê´€ë ¨ ë¬¸ì¥ì´ë©´ì„œ ì§„ë‹¨ ìš©ì–´ê°€ ì—†ëŠ” ê²½ìš°ë§Œ í¬í•¨
                    if has_complication and topic_ok and not has_diagnostic and not has_irrelevant_domain and total_length + len(sentence) <= 150:
                        core_sentences.append(sentence)
                        total_length += len(sentence)
                        if len(core_sentences) >= 2:  # ìµœëŒ€ 2ë¬¸ì¥
                            break
                else:
                    # ì¼ë°˜ ì§ˆì˜: ì§„ë‹¨ ìš©ì–´ê°€ ì—†ëŠ” ë¬¸ì¥ë§Œ í¬í•¨
                    if topic_ok and not has_diagnostic and not has_irrelevant_domain and total_length + len(sentence) <= 150:
                        core_sentences.append(sentence)
                        total_length += len(sentence)
                        if len(core_sentences) >= 2:  # ìµœëŒ€ 2ë¬¸ì¥
                            break
            
            if core_sentences:
                main_info = '. '.join(core_sentences) + '.'
            else:
                # ì ì ˆí•œ ë¬¸ì¥ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ë©”ì‹œì§€
                if 'í•©ë³‘ì¦' in query.lower():
                    main_info = "Aí˜•ê°„ì—¼ì˜ í•©ë³‘ì¦ì— ëŒ€í•œ ì •ë³´ê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤."
                else:
                    # ì§ˆí™˜ëª…ì„ ë³´ì¡´í•˜ì—¬ ë³´ë‹¤ êµ¬ì²´ì ìœ¼ë¡œ í‘œì‹œ
                    if any(t in query.lower() for t in ['aí˜•ê°„ì—¼', 'aí˜• ê°„ì—¼', 'aí˜•ê°ì—¼', 'hepatitis a']):
                        main_info = "Aí˜•ê°„ì—¼ ê´€ë ¨ ì •ë³´ê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤."
                    else:
                        main_info = "ê´€ë ¨ ì˜ë£Œ ì •ë³´ê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤."
        except:
            main_info = "ê´€ë ¨ ì˜ë£Œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    else:
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì‹ ë¢°ë„ê°€ ë‚®ì€ ê²½ìš°
        if (result.judgment or '') == "ë¯¼ê°„ìš”ë²• ê´€ë ¨ ì •ë³´":
            main_info = "í•´ë‹¹ ì£¼ì¥ì€ ë¯¼ê°„ìš”ë²•ì— í•´ë‹¹í•˜ë©° ê³¼í•™ì  ê·¼ê±°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."
        else:
            corrected = result.corrected_info or "ì¶”ê°€ ê²€ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤."
            # ì •ì • ì •ë³´ë„ ê¸¸ì´ ì œí•œ (ìµœëŒ€ 100ì)
            if len(corrected) > 100:
                sentences = corrected.split('.')
                main_info = sentences[0] + '.' if sentences else corrected[:97] + "..."
            else:
                main_info = corrected
    
    # ê°„ë‹¨ ì •ë¦¬/ì •ì œ í•¨ìˆ˜
    import re as _re
    def _sanitize(txt: str) -> str:
        if not txt:
            return ''
        s = txt
        # ì¼ë³¸ì–´/íƒœêµ­ì–´ ë“± ë¹„í•œê¸€ ìŠ¤í¬ë¦½íŠ¸ ì œê±°
        s = _re.sub(r'[\u3040-\u30FF\u31F0-\u31FF\uFF65-\uFF9F\u0E00-\u0E7F]+', '', s)
        # ë¶ˆí•„ìš”í•œ ê¸€ë¨¸ë¦¬í‘œ/ì¤‘ë³µ ê³µë°± ì œê±°
        s = s.replace('â€¢', ' ').replace('-', ' ').replace('Â·', ' ')
        s = _re.sub(r'\s{2,}', ' ', s)
        # íŠ¹ì • íŒ¨í„´ë§Œ ë³´ì • (ê³¼ë„ ê²°í•© ë°©ì§€)
        s = _re.sub(r'ìˆ\s*ìŠµ\s*ë‹ˆ\s*ë‹¤', 'ìˆìŠµë‹ˆë‹¤', s)
        s = _re.sub(r'ì—†\s*ìŠµ\s*ë‹ˆ\s*ë‹¤', 'ì—†ìŠµë‹ˆë‹¤', s)
        s = _re_sub(r'ë©\s*ë‹ˆ\s*ë‹¤', 'ë©ë‹ˆë‹¤', s) if '_re_sub' in globals() else _re.sub(r'ë©\s*ë‹ˆ\s*ë‹¤', 'ë©ë‹ˆë‹¤', s)
        # ë°˜ë³µ ì ‘ë‘ì–´ ì œê±°
        s = _re.sub(r'^í•©ë³‘ì¦\s+(?=Aí˜•ê°„ì—¼ì˜\s+í•©ë³‘ì¦)', '', s)
        s = _re.sub(r'\s+', ' ', s).strip()
        return s

    # ì¢…ê²°/ì´ìƒ ê³µë°±/íŠ¹ì • íŒ¨í„´ ë³´ì •
    main_info = _sanitize(main_info)
    main_info = _re.sub(r'ìˆ\s*ìŠµ\s*ë‹ˆ\s*ë‹¤', 'ìˆìŠµë‹ˆë‹¤', main_info)
    main_info = _re.sub(r'ì—†\s*ìŠµ\s*ë‹ˆ\s*ë‹¤', 'ì—†ìŠµë‹ˆë‹¤', main_info)
    main_info = _re.sub(r'ë©\s*ë‹ˆ\s*ë‹¤', 'ë©ë‹ˆë‹¤', main_info)
    if main_info.endswith('ë‚´ìš©ì€.'):
        main_info = "ê´€ë ¨ëœ ì˜í•™ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    # ë³´ê³ ì„œ êµ¬ì„±: íŒë‹¨ ìœ í˜•ì— ë”°ë¼ ì„¹ì…˜í™”
    is_reliable = (result.judgment or '') == 'ì˜¬ë°”ë¥¸ ì˜ë£Œ ì •ë³´'
    is_unreliable = (result.judgment or '') == 'ì˜¬ë°”ë¥´ì§€ ì•Šì€ ì •ë³´'

    if is_reliable or is_unreliable:
        report = f"""{judgment_label}

{status} ({result.confidence_score:.0f}% ì •í™•ë„)

ğŸ”¬ ì˜í•™ì  ì„¤ëª…
í•µì‹¬ ì„¤ëª…
{main_info}

ğŸ’¡
{result.reason}"""
    else:
        # íŒë‹¨í•˜ê¸° ì–´ë ¤ì›€/ë¯¼ê°„ìš”ë²•: í•µì‹¬/ì¶”ê°€ ì„¤ëª… ìˆ¨ê¸°ê³  íŒë‹¨ ê·¼ê±°ë§Œ
        only_reason = result.reason or 'ì œê³µëœ ê·¼ê±°ë§Œìœ¼ë¡œ ì •í™•ì„±ì„ ë‹¨ì •í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.'
        report = f"""{judgment_label}

{status} ({result.confidence_score:.0f}% ì •í™•ë„)

ğŸ”¬ ì˜í•™ì  ì„¤ëª…
ğŸ’¡
{only_reason}"""
    
    return report.strip()